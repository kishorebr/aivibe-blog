---
title: Tesla found partially liable for a deadly 2019 crash
date: '2025-08-01'
excerpt: >-
  A jury in Florida has found Tesla partially liable for a 2019 crash involving
  the company&#39;s Autopilot self-driving feature, The Washington Post re...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Work
  - Transportation
category: Work
source: >-
  https://www.engadget.com/transportation/evs/tesla-found-partially-liable-for-a-deadly-2019-crash-193612682.html?src=rss
---
<p>A jury in Florida has found Tesla partially liable for a 2019 crash involving the company&#39;s Autopilot self-driving feature, <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" class="no-affiliate-link" href="https://www.washingtonpost.com/technology/2025/08/01/tesla-found-partially-liable-fatal-2019-crash-involving-driver-assistance-technology-jury-orders-200-million-damages/?location=alert"><em>The Washington Post </em>reports</a>. As a result, the company will have to pay $43 million in compensatory damages and even more in punitive damages.</p>
<p>Autopilot comes pre-installed on Tesla&#39;s cars and handles things like collision detection and emergency braking. Tesla has mostly avoided taking responsibility for crashes involving cars with the Autopilot<em>&nbsp;</em>enabled, but the Florida case played out differently. The jury ultimately decided that the self-driving tech enabled driver George McGee to take his eyes off the road and hit a couple, Naibel Benavides Leon and Dillon Angulo, ultimately killing one and severely injuring the other.&nbsp;</p>
<span id="end-legacy-contents"></span><p>During the case, Tesla&#39;s lawyers argued that McGee&#39;s decision to take his eyes off the road to reach for his phone was the cause of the crash, and that Autopilot shouldn&#39;t be considered. The plaintiffs, Angulo and Benevides Leon&#39;s family, argued that the way Tesla and Elon Musk talked about the feature ultimately created the illusion that Autopilot was safer than it really was. &quot;My concept was that it would assist me should I have a failure … or should I make a mistake,&quot; McGee said on the stand. &quot;And in that case I feel like it failed me.&quot; The jury ultimately assigned two-thirds of the responsibility to McGee and a third to Tesla, <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" class="no-affiliate-link" href="https://www.nbcnews.com/news/us-news/tesla-autopilot-crash-trial-verdict-partly-liable-rcna222344">according to <em>NBC News</em></a>.</p>
<p>When reached for comment, Tesla said it would appeal the decision and gave the following statement:&nbsp;</p>
<blockquote><p>Today’s verdict is wrong and only works to set back automotive safety and jeopardize Tesla’s and the entire industry’s efforts to develop and implement life-saving technology. We plan to appeal given the substantial errors of law and irregularities at trial. Even though this jury found that the driver was overwhelmingly responsible for this tragic accident in 2019, the evidence has always shown that this driver was solely at fault because he was speeding, with his foot on the accelerator – which overrode Autopilot – as he rummaged for his dropped phone without his eyes on the road. To be clear, no car in 2019, and none today, would have prevented this crash. This was never about Autopilot; it was a fiction concocted by plaintiffs’ lawyers blaming the car when the driver – from day one – admitted and accepted responsibility.&nbsp;</p></blockquote>
<p>In a National Highway Traffic Safety Administration <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1" class="no-affiliate-link" href="https://www.engadget.com/nhtsa-concludes-tesla-autopilot-investigation-after-linking-the-system-to-14-deaths-161941746.html">investigation of Autopilot</a> from 2024, crashes were blamed on driver misuse of Tesla&#39;s system and not the system itself. The NHTSA also found that Autopilot was overly permissive and &quot;did not adequately ensure that drivers maintained their attention on the driving task,&quot; which lines up with the 2019 Florida crash.</p>
<p>While Autopilot is only one component of Tesla&#39;s larger collection of self-driving driving features, selling the idea that the company&#39;s cars could safely driving on their own is a key part of its future. Elon Musk <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" class="no-affiliate-link" href="https://x.com/elonmusk/status/1727484899374899687">has claimed</a> that Full Self-Driving (FSD), the paid upgrade to Autopilot, is &quot;safer than human driving.&quot; <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1" class="no-affiliate-link" href="https://www.engadget.com/transportation/teslas-first-robotaxi-rides-kick-off-in-austin-texas-100015076.html">Tesla&#39;s Robotaxi service</a> relies on FSD being able to function with no or minimal supervision, something that produced <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1" class="no-affiliate-link" href="https://www.engadget.com/transportation/teslas-first-robotaxi-rides-are-already-running-into-a-few-bumps-205308245.html">mixed results</a> in the first few days the service was available.&nbsp;</p>
<p><strong>Update, August 1, 6:05PM ET: </strong>This story was updated after publication to include Tesla&#39;s statement.</p>This article originally appeared on Engadget at https://www.engadget.com/transportation/evs/tesla-found-partially-liable-for-a-deadly-2019-crash-193612682.html?src=rss
