---
title: Benchmark raises $225M in special funds to double down on Cerebras
date: '2026-02-07'
excerpt: >-
  This week, AI chipmaker Cerebras Systems announced that it raised $1 billion
  in fresh capital at a valuation of $23 billion — a nearly threefold incre...
coverImage: >-
  https://images.unsplash.com/photo-1559526324-4b87b5e36e44?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Work
category: Finance
source: >-
  https://techcrunch.com/2026/02/06/benchmark-raises-225m-in-special-funds-to-double-down-on-cerebras/
---
This week, AI chipmaker Cerebras Systems announced that it raised $1 billion in fresh capital at a valuation of $23 billion — a nearly threefold increase from the $8.1 billion valuation the Nvidia rival had reached just six months earlier.

While the round was led by Tiger Global, a huge part of the new capital came from one of the company’s earliest backers: Benchmark Capital. The prominent Silicon Valley firm invested at least $225 million in Cerebras’ latest round, according to a person familiar with the deal.


	
	




	
	



Benchmark first bet on 10-year-old Cerebras when it led the startup’s $27 million Series A in 2016. Since Benchmark deliberately keeps its funds under $450 million, the firm raised two separate vehicles, both called ‘Benchmark Infrastructure,’ according to regulatory filings. According to the person familiar with the deal, these vehicles were created specifically to fund the Cerebras investment.

Benchmark declined to comment.

What sets Cerebras apart is the sheer physical scale of its processors. The company’s Wafer Scale Engine, its flagship chip announced in 2024, measures approximately 8.5 inches on each side and packs 4 trillion transistors into a single piece of silicon. To put that in perspective, the chip is manufactured from nearly an entire 300-millimeter silicon wafer, the circular discs that serve as the foundation for all semiconductor production. Traditional chips are thumbnail-sized fragments cut from these wafers; Cerebras instead uses almost the whole circle.

This architecture delivers 900,000 specialized cores working in parallel, allowing the system to process AI calculations without shuffling data between multiple separate chips (a major bottleneck in conventional GPU clusters). The company says the design enables AI inference tasks to run more than 20 times faster than competing systems.

The funding comes as Cerebras, based in Sunnyvale, Calif., gains momentum in the AI infrastructure race. Last month, Cerebras signe
