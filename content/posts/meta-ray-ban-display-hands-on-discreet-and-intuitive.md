---
title: 'Meta Ray-Ban Display hands-on: Discreet and intuitive'
date: '2025-09-19'
excerpt: >-
  I&#39;ve been testing smart glasses for almost a decade. And in that time, one
  of the questions I&#39;ve been asked the most is &quot;oh, but can you...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Work
category: Work
source: >-
  https://www.engadget.com/wearables/meta-ray-ban-display-hands-on-discreet-and-intuitive-002334346.html?src=rss
---
<p>I&#39;ve been testing smart glasses for almost a decade. And in that time, one of the questions I&#39;ve been asked the most is &quot;oh, but can you see anything in them?&quot; For years, I had to explain that no, glasses like that don&#39;t really exist yet.</p>
<p>That&#39;s no longer the case. And while I&#39;ve seen a bunch of glasses over the last year that have some kind of display, the Meta Ray-Ban Display glasses feel the closest to fulfilling what so many people envision when they hear the words &quot;smart glasses.&quot;</p>
<span id="end-legacy-contents"></span><p>To be clear, they don&#39;t offer the kind of immersive AR that&#39;s possible with <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/ar-vr/metas-orion-prototype-offers-a-glimpse-into-our-ar-future-123038066.html">Meta&#39;s Orion prototype</a>. In fact Meta considers &quot;display AI glasses&quot; to be a totally separate category from AR. The display is only on one lens — the right — and its 20-degree field of view is much smaller than the 70 degrees on Orion. That may sound like a big compromise, but it doesn&#39;t feel like one.</p>
<figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/30113ea0-94ea-11f0-b5ef-5d7b928050e5" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/30113ea0-94ea-11f0-b5ef-5d7b928050e5" style="height:1280px;width:1920px;" alt="The Meta Ray-Ban Display glasses." data-uuid="6feaa76a-42bd-3213-aa1f-37d4da20ad79"><figcaption></figcaption><div class="photo-credit">Karissa Bell for Engadget</div></figure>
<p>The single display feels much more practical for a pair of glasses you&#39;ll want to wear every day. It&#39;s meant to be something you can glance at when you need it, not an always-on overlay. The smaller size also means that the display is much sharper, at 42 pixels per degree. This was especially noticeable when I walked outside with the glasses on; images on the display looked even sharper than in indoor light, thanks to automatic brightness features.</p>
<p>I also appreciated that you can&#39;t see any light from the display when you&#39;re looking at someone wearing the glasses. In fact the display is only barely noticeable at all when you at them up close.&nbsp;</p>
<p>Having a smaller display also means that the glasses are cheaper, at $799, and that they don&#39;t look like the chunky AR glasses we&#39;ve seen so many times. At 69 grams, they are a bit heavier and thicker than the second-gen Meta Ray-Bans, but not much. As someone who has tried on way too many pairs of thick black smart glasses, I&#39;m glad Meta is offering these in a color besides black. All Wayfarer-style frames look wide on my face but the lighter &quot;sand&quot; color feels a lot more flattering.</p>
<figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/ebd71e80-94e9-11f0-b579-e622f4760786" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/ebd71e80-94e9-11f0-b579-e622f4760786" style="height:1080px;width:1920px;" alt="The Meta Ray-Ban Display (left) and second-gen Ray-Ban Meta glasses (right.) The display glasses a little thicker." data-uuid="6d8aeb21-16fa-3814-852c-80f9bbba4c52"><figcaption>The Meta Ray-Ban Display (left) and second-gen Ray-Ban Meta glasses (right.) The display glasses are a little thicker.</figcaption><div class="photo-credit">Karissa Bell for Engadget</div></figure>
<p>The Meta Neural Band wristband that comes with the display glasses functions pretty much the same as the band I used on the Orion prototype. It uses sensors to detect the subtle muscle movements on your hand and wrist and can translate that into actions within the glasses&#39; interface.</p>
<p>It&#39;s hard to describe, but the gestures for navigating the glasses interfaces work surprisingly well. I can see how it could take a little time to get used to the various gestures for navigating between apps, bringing up Meta AI, adjusting the volume and other actions, but they are all fairly intuitive. For example, you use your thumb to swipe along the the top of your index finger, sort of like a D-pad, to move up and down and side to side. And you can raise and lower the speaker volume by holding your thumb and index finger together and rotating your wrist right or left like it&#39;s a volume knob.</p>
<p>It&#39;s no secret that Meta&#39;s ultimate goal for its smart glasses is to replace, or almost replace, your phone. That&#39;s not possible yet, but having an actual display means you can look at your phone a whole lot less.</p>
<figure><img src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/cd5d5770-94ea-11f0-9bd9-beed797f3ad5" data-crop-orig-src="https://s.yimg.com/os/creatr-uploaded-images/2025-09/cd5d5770-94ea-11f0-9bd9-beed797f3ad5" style="height:1280px;width:1920px;" alt="The Neural Wristband." data-uuid="b1c4c4ed-892e-3f74-9f71-1ac40e2d8250"><figcaption></figcaption><div class="photo-credit">Karissa Bell for Engadget</div></figure>
<p>The display can surface incoming texts, navigation with map previews (for walking directions), and info from your calendar. I was also able to take a video call from the glasses — unlike Mark Zuckerberg&#39;s attempted live demo during his keynote — and it was way better than I expected. I could not only clearly see the person I was talking to and their surroundings, I could turn on my glasses&#39; camera and see a smaller version of the video from my side.</p>
<p>I also got a chance to try the Conversational Focus feature, which allows you to get live captions of the person you&#39;re speaking with even in a loud environment that may be hard to hear. There was something very surreal about getting real-time subtitles to a conversation with a person standing  directly in front of me. As someone who tries really hard to not look at screens when I&#39;m speaking to people, it almost felt a little wrong. But I can also see how this would be incredibly helpful to people who have trouble hearing or processing conversations. It would also be great for translations, something Meta AI already does very well.</p>
<core-slideshow data-slideshowid="984ad0dd-ca99-4a06-9688-02bfb2be8fa4"/>
<p>I also appreciated that the wristband allows you to invoke Meta AI with a gesture so you don&#39;t always have to say &quot;Hey Meta.&quot; It&#39;s a small change, but I&#39;ve always felt weird about talking to Meta AI in public. The display also addresses another one of my longtime gripes with the Ray-Ban Meta and Oakley glasses: framing a photo is really difficult. But with a display, you can see a preview of your shot, as well as the photo after the fact, so you no longer have to just snap a bunch and hope for the best.</p>
<p>I&#39;ve only had about 30 minutes with the glasses, so I don&#39;t really know how having a display could fit into my daily routine. But even after a short time with them, they really do feel like the beginning of the kind of smart glasses a lot of people have been waiting for.</p>This article originally appeared on Engadget at https://www.engadget.com/wearables/meta-ray-ban-display-hands-on-discreet-and-intuitive-002334346.html?src=rss
