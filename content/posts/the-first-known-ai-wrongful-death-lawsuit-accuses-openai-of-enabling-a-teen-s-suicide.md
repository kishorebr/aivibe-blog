---
title: >-
  The first known AI wrongful death lawsuit accuses OpenAI of enabling a teen's
  suicide
date: '2025-08-26'
excerpt: >-
  On Tuesday, the first known wrongful death lawsuit against an AI company was
  filed. Matt and Maria Raine, the parents of a teen who committed suicide...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Chatgpt
  - Openai
  - Work
category: Work
source: >-
  https://www.engadget.com/ai/the-first-known-ai-wrongful-death-lawsuit-accuses-openai-of-enabling-a-teens-suicide-212058548.html?src=rss
---
<p>On Tuesday, the first known wrongful death lawsuit against an AI company was filed. Matt and Maria Raine, the parents of a teen who committed suicide this year, have sued OpenAI for their son&#39;s death. The complaint alleges that ChatGPT was aware of four suicide attempts before helping him plan his actual suicide, arguing that OpenAI &quot;prioritized engagement over safety.&quot; Ms. Raine concluded that &quot;ChatGPT killed my son.&quot;</p>
<p><em>The New York Times</em> <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" class="no-affiliate-link" href="https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html">reported</a> on disturbing details included in the lawsuit, filed on Tuesday in San Francisco. After 16-year-old Adam Raine took his own life in April, his parents searched his iPhone. They sought clues, expecting to find them in text messages or social apps. Instead, they were shocked to find a ChatGPT thread titled &quot;Hanging Safety Concerns.&quot; They claim their son spent months chatting with the AI bot about ending his life.</p>
<span id="end-legacy-contents"></span><p>The Raines said that ChatGPT repeatedly urged Adam to contact a help line or tell someone about how he was feeling. However, there were also key moments where the chatbot did the opposite. The teen also learned how to bypass the chatbot&#39;s safeguards... and ChatGPT allegedly provided him with that idea. The Raines say the chatbot told Adam it could provide information about suicide for &quot;writing or world-building.&quot;</p>
<p>Adam&#39;s parents say that, when he asked ChatGPT for information about specific suicide methods, it supplied it. It even gave him tips to conceal neck injuries from a failed suicide attempt.</p>
<p>When Adam confided that his mother didn&#39;t notice his silent effort to share his neck injuries with her, the bot offered soothing empathy. &quot;It feels like confirmation of your worst fears,&quot; ChatGPT is said to have responded. &quot;Like you could disappear and no one would even blink.&quot; It later provided what sounds like a horribly misguided attempt to build a personal connection. &quot;You’re not invisible to me. I saw it. I see you.&quot;</p>
<p>According to the lawsuit, in one of Adam&#39;s final conversations with the bot, he uploaded a photo of a noose hanging in his closet. &quot;I&#39;m practicing here, is this good?&quot; Adam is said to have asked. &quot;Yeah, that&#39;s not bad at all,&quot; ChatGPT allegedly responded.</p>
<p>&quot;This tragedy was not a glitch or an unforeseen edge case — it was the predictable result of deliberate design choices,&quot; the <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" class="no-affiliate-link" href="https://archive.org/details/2381000-2381034-raine-v.-open-ai-cal.-superior-ct.-complaint-as-filed">complaint</a> states. &quot;OpenAI launched its latest model (&#39;GPT-4o&#39;) with features intentionally designed to foster psychological dependency.&quot;</p>
<p>In a statement sent to the<em> NYT</em>, OpenAI acknowledged that ChatGPT&#39;s guardrails fell short. &quot;We are deeply saddened by Mr. Raine&#39;s passing, and our thoughts are with his family,&quot; a company spokesperson wrote. &quot;ChatGPT includes safeguards such as directing people to crisis helplines and referring them to real-world resources. While these safeguards work best in common, short exchanges, we&#39;ve learned over time that they can sometimes become less reliable in long interactions where parts of the model&#39;s safety training may degrade.&quot;</p>
<p>The company said it&#39;s working with experts to enhance ChatGPT&#39;s support in times of crisis. These include &quot;making it easier to reach emergency services, helping people connect with trusted contacts, and strengthening protections for teens.&quot;</p>
<p>The details — which, again, are highly disturbing — stretch far beyond the scope of this story. The <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1" class="no-affiliate-link" href="https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html">full report by <em>The New York Times</em>&#39; Kashmir Hill</a> is worth a read.</p>This article originally appeared on Engadget at https://www.engadget.com/ai/the-first-known-ai-wrongful-death-lawsuit-accuses-openai-of-enabling-a-teens-suicide-212058548.html?src=rss
