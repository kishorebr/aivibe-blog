---
title: >-
  How a simple link allowed hackers to bypass Copilot's security guardrails -
  and what Microsoft did about it
date: '2026-01-19'
excerpt: >-
  Tech Home Tech Security How a simple link allowed hackers to bypass Copilot's
  security guardrails - and what Microsoft did about it Reprompt let attac...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
category: General AI
source: >-
  https://www.zdnet.com/article/copilot-steal-data-reprompt-vulnerability-microsoft/
---
Tech      
      Home
    
      Tech
    
      Security
       
    How a simple link allowed hackers to bypass Copilot's security guardrails - and what Microsoft did about it
     
    Reprompt let attackers control Copilot and pull your data, even after you closed the chat.
      Written by 
            Charlie Osborne, Contributing WriterContributing Writer  Jan. 18, 2026 at 6:00 p.m. PT                            Ernesto r. Ageitos/Moment/Getty ImagesFollow ZDNET: Add us as a preferred source on Google.  	ZDNET's key takeaways  Dubbed "Reprompt," the attack used a URL parameter to steal user data.A single click was enough to trigger the entire attack chain.Attackers could pull sensitive Copilot data, even after the window closed.Researchers have revealed a new attack that required only one click to execute, bypassing Microsoft Copilot security controls and enabling the theft of user data.Also: How to remove Copilot AI from Windows 11 today  	Meet Reprompt  On Wednesday, Varonis Threat Labs published new research documenting Reprompt, a new attack method that affected Microsoft's Copilot AI assistant.  Reprompt impacted Microsoft Copilot Personal and, according to the team, gave "threat actors an invisible entry point to perform a data‑exfiltration chain that bypasses enterprise security controls entirely and accesses sensitive data without detection -- all from one click."Also: AI PCs aren't selling, and Microsoft's PC partners are scramblingNo user interaction with Copilot or plugins was required for this attack to trigger. Instead, victims had to click a link. After this single click, Reprompt could circumvent security controls by abusing the 'q' URL parameter to feed a prompt and malicious actions through to Copilot, potentially allowing an attacker to ask for data previously submitted by the user -- including personally identifiable information (PII)."The attacker maintains control even when the Copilot chat is closed, allowing the victim's session to be s
