---
title: >-
  AI is becoming introspective - and that 'should be monitored carefully,' warns
  Anthropic
date: '2025-11-03'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence AI is becoming
  introspective - and that 'should be monitored carefully,' warns Anthropic
  Models tha...
coverImage: >-
  https://images.unsplash.com/photo-1549317661-bd32c8ce0db2?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
category: Transportation
source: >-
  https://www.zdnet.com/article/ai-is-becoming-introspective-and-that-should-be-monitored-carefully-warns-anthropic/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    AI is becoming introspective - and that 'should be monitored carefully,' warns Anthropic
     
    Models that introspect on their own thoughts could be a huge boon for researchers - or pose a threat to humans.
      Written by 
            Webb Wright, Contributing WriterContributing Writer  Nov. 2, 2025 at 7:00 p.m. PT                            Just_Super/E+/Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysClaude shows limited introspective abilities, Anthropic said.The study used a method called "concept injection."It could have big implications for interpretability research.One of the most profound and mysterious capabilities of the human brain (and perhaps those of some other animals) is introspection, which means, literally, "to look within." You're not just thinking, you're aware that you're thinking -- you can monitor the flow of your mental experiences and, at least in theory, subject them to scrutiny. The evolutionary advantage of this psychotechnology can't be overstated. "The purpose of thinking," Alfred North Whitehead is often quoted as saying, "is to let the ideas die instead of us dying."Also: I tested Sora's new 'Character Cameo' feature, and it was borderline disturbingSomething similar might be happening beneath the hood of AI, new research from Anthropic found.On Wednesday, the company published a paper titled "Emergent Introspective Awareness in Large Language Models," which showed that in some experimental conditions, Claude appeared to be capable of reflecting upon its own internal states in a manner vaguely resembling human introspection. Anthropic tested a total of 16 versions of Claude; the two most advanced models, Claude Opus 4 and 4.1, demonstrated a higher degree of introspection, suggesting that this capacity could increase as AI advances."Our results demonstrate that modern language models possess at l
