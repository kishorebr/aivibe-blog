---
title: >-
  How Google's new AI model protects user privacy without sacrificing
  performance
date: '2025-09-16'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence How Google's new AI model
  protects user privacy without sacrificing performance Google researchers...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Llm
  - Work
category: Work
source: >-
  https://www.zdnet.com/article/how-googles-new-ai-model-protects-user-privacy-without-sacrificing-performance/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    How Google's new AI model protects user privacy without sacrificing performance
     
    Google researchers unveil VaultGemma, an LLM designed to generate high-quality outputs without memorizing training data. Here's how it works.
      Written by 
            Webb Wright, Contributing WriterContributing Writer  Sept. 16, 2025 at 12:41 p.m. PT                           picture alliance/Contributor/picture alliance via Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysAI developers are trying to balance model utility with user privacy.New research from Google suggests a possible solution.The results are promising, but much work remains to be done.AI developers have long faced a dilemma: The more training data you feed a large language model (LLM), the more fluent and human-like its output will be. However, at the same time, you run the risk of including sensitive personal information in that dataset, which the model could then republish verbatim, leading to major security compromises for the individuals affected and damaging PR scandals for the developers.Â How does one balance utility with privacy?Also: Does your generative AI protect your privacy? Study ranks them best to worstNew research from Google claims to have found a solution -- a framework for building LLMs that will optimize user privacy without any major degradations in the AI's performance.Last week, a team of researchers from Google Research and Google DeepMind unveiled VaultGemma, an LLM designed to generate high-quality outputs without memorizing its training data verbatim. The result: Sensitive information that makes it into the training dataset won't get republished.Digital noiseThe key ingredient behind VaultGemma is a mathematical framework known as differential privacy (DP), which is essentially digital noise that scrambles the model's ability to perfectly memorize 
