---
title: 'AI isn''t getting smarter, it''s getting more power hungry - and expensive'
date: '2026-02-13'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence AI isn't getting smarter,
  it's getting more power hungry - and expensive Frontier models such as Op...
coverImage: >-
  https://images.unsplash.com/photo-1559526324-4b87b5e36e44?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Openai
category: Finance
source: >-
  https://www.zdnet.com/article/ai-isnt-getting-smarter-its-getting-more-expensive-mit-report-finds/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    AI isn't getting smarter, it's getting more power hungry - and expensive
     
    Frontier models such as OpenAI's GPT depend mostly on increasing computing power rather than smarter algorithms, according to a new MIT report. Here's why that matters.
      Written by 
            Tiernan Ray, Senior Contributing WriterSenior Contributing Writer  Feb. 12, 2026 at 6:01 p.m. PT                            Quardia/iStock/Getty Images Plus via Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysMIT estimated the computing power for 809 large language models.Total compute affected AI accuracy more than any algorithmic tricks.Computing power will continue to dominate AI development.It's well known that artificial intelligence models such as GPT-5.2 improve their performance on benchmark scores as more compute is added. It's a phenomenon known as "scaling laws," the AI rule of thumb that says accuracy improves in proportion to computing power.But, how much effect does computing power have relative to other things that OpenAI, Google, and others bring -- such as better algorithms or different data?  To find the answer, researchers Matthias Mertens and colleagues of the Massachusetts Institute of Technology examined data for 809 large language model AI programs. They estimated how much of each benchmark's performance was attributable to the amount of computing power used to train the models. Also: Why you'll pay more for AI in 2026, and 3 money-saving tips to tryThey then compared that figure to the amount likely attributable to a company's unique engineering or algorithmic innovation, what they call the "secret sauce," which is sometimes -- but not always -- disclosed. And they compared general improvements in AI across the entire developer community and shared tips and tricks that consistently improve model performance.  Their results are report
