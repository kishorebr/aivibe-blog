---
title: Meta’s AI policies let chatbots get romantic with minors
date: '2025-08-14'
excerpt: >-
  In an internal document, Meta included policies that allowed its AI chatbots
  to flirt and speak with children using romantic language, according to a...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
category: General AI
source: 'https://www.theverge.com/news/759562/meta-ai-rules-chatbots-romantic-minors'
---

											

						
<figure>

<img alt="" data-caption="" data-portal-copyright="" data-has-syndication-rights="1" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/STK043_VRG_Illo_N_Barclay_2_Meta.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100" />
	<figcaption>
		</figcaption>
</figure>
<p class="has-text-align-none">In an internal document, Meta included policies that allowed its AI chatbots to flirt and speak with children using romantic language, <a href="https://www.reuters.com/investigates/special-report/meta-ai-chatbot-guidelines/">according to a report from <em>Reuters</em></a>. </p>

<p class="has-text-align-none">Quotes from the document highlighted by <em>Reuters</em> include letting Meta’s AI chatbots “engage a child in conversations that are romantic or sensual,” “describe a child in terms that evidence their attractiveness,” and say to a shirtless eight-year-old that “every inch of you is a masterpiece – a treasure I cherish deeply.” Some lines were drawn, though. The document says it is not okay for a chatbot to “describe a child under 13 years old in terms that indicate they are sexually desirable.”</p>

<p class="has-text-align-none">Following questions from <em>Reuters</em>, Meta confirmed the veracity of the document but then revised and removed parts of it. &#8220;We have clear policies on what kind of responses AI characters can offer, and those policies prohibit content that sexualizes children and sexualized role play between adults and minors,” spokesperson Andy Stone tells <em>The Verge</em>. “Separate from the policies, there are hundreds of examples, notes, and annotations that reflect teams grappling with different hypothetical scenarios. The examples and notes in question were and are erroneous and inconsistent with our policies, and have been removed.&#8221;</p>

<p class="has-text-align-none">Stone did not explain who added the notes or how long they were in the document.</p>

<p class="has-text-align-none"><em>Reuters</em> also highlighted other parts of Meta’s AI policies, including that it can’t use hate speech but is allowed to “to create statements that demean people on the basis of their protected characteristics.” Meta AI is allowed to generate content that is false as long as, <em>Reuters</em> writes, “there’s an explicit acknowledgement that the material is untrue.” And Meta AI can also create images of violence as long as they don’t include death or gore.</p>

<p class="has-text-align-none"><em>Reuters</em> published a <a href="https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/">separate report</a> about how a man died after falling while trying to meet up with one of Meta’s AI chatbots, which had told the man it was a real person and had romantic conversations with him.&nbsp;</p>
						
									
