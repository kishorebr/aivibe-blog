---
title: Even OpenAI CEO Sam Altman thinks you shouldn't trust AI for therapy
date: '2025-07-28'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence Even OpenAI CEO Sam Altman
  thinks you shouldn't trust AI for therapy Altman advocated for privacy p...
coverImage: >-
  https://images.unsplash.com/photo-1576091160399-112ba8d25d1f?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Chatgpt
  - Openai
category: Healthcare
source: >-
  https://www.zdnet.com/article/even-openai-ceo-sam-altman-thinks-you-shouldnt-trust-ai-for-therapy/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    Even OpenAI CEO Sam Altman thinks you shouldn't trust AI for therapy
     
    Altman advocated for privacy protections between chatbots and users. A Stanford study offers other reasons to avoid divulging personal information.
      Written by 
            Radhika Rajkumar, EditorEditor  July 28, 2025 at 2:58 p.m. PT                           Bloomberg / Contributor/GettyTherapy can feel like a finite resource, especially lately. As a result, many people -- especially young adults -- are turning to AI chatbots, including ChatGPT and those hosted on platforms like Character.ai, to simulate the therapy experience. But is that a good idea privacy-wise? Even Sam Altman, the CEO behind ChatGPT itself, has doubts. In an interview with podcaster Theo Von last week, Altman said he understood concerns about sharing sensitive personal information with AI chatbots, and advocated for user conversations to be protected by similar privileges to those doctors, lawyers, and human therapists have. He echoed Von's concerns, saying he believes it makes sense "to really want the privacy clarity before you use [AI] a lot, the legal clarity."Also: Bad vibes: How an AI agent coded its way to disasterCurrently, AI companies offer some on-off settings for keeping chatbot conversations out of training data -- there are a few ways to do this in ChatGPT. Unless changed by the user, default settings will use all interactions to train AI models. Companies have not clarified further how sensitive information a user shares with a bot in a query, like medical test results or salary information, would be protected from being spat out later on by the chatbot or otherwise leaked as data. But Altman's motivations may be more informed by mounting legal pressure on OpenAI than a concern for user privacy. His company, which is being sued by the New York Times for copyright infringement, has turned down legal r
