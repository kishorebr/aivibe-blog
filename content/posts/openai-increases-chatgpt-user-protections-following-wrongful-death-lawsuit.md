---
title: OpenAI increases ChatGPT user protections following wrongful death lawsuit
date: '2025-08-28'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence OpenAI increases ChatGPT
  user protections following wrongful death lawsuit New guardrails provide p...
coverImage: >-
  https://images.unsplash.com/photo-1576091160399-112ba8d25d1f?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Chatgpt
  - Openai
category: Healthcare
source: >-
  https://www.zdnet.com/article/openai-increases-chatgpt-user-protections-following-wrongful-death-lawsuit/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    OpenAI increases ChatGPT user protections following wrongful death lawsuit
     
    New guardrails provide parents with more control over their kids' chatbot use.
      Written by 
            Nina Raemont, Editor, Wearables & Health TechEditor, Wearables & Health Tech  Aug. 28, 2025 at 1:05 p.m. PT                            Yifei Fang/Moment via Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeaways OpenAI is giving ChatGPT new safeguards. A teen recently used ChatGPT to learn how to take his life. OpenAI may add further parental controls for young users.ChatGPT doesn't have a good track record of intervening when a user is in emotional distress, but several updates from OpenAI aim to change that. The company is building on how its chatbot responds to distressed users by strengthening safeguards, updating how and what content is blocked, expanding intervention, localizing emergency resources, and bringing a parent into the conversation when needed, the company announced on Thursday. In the future, a guardian might even be able to see how their kid is using the chatbot.   Also: Patients trust AI's medical advice over doctors - even when it's wrong, study findsPeople go to ChatGPT for everything, including advice, but the chatbot might not be equipped to handle the more sensitive queries some users are asking. OpenAI CEO Sam Altman himself said he wouldn't trust AI for therapy, citing privacy concerns; A recent Stanford study detailed how chatbots lack the critical training human therapists have to identify when a person is a danger to themselves or others, for example. Teen suicides connected to chatbotsThose shortcomings can result in heartbreaking consequences. In April, a teen boy who had spent hours discussing his own suicide and methods with ChatGPT eventually took his own life. His parents have filed a lawsuit against OpenAI that s
