---
title: >-
  Anthropic accuses three Chinese AI labs of abusing Claude to improve their own
  models
date: '2026-02-23'
excerpt: >-
  Anthropic is issuing a call to action against AI &quot;distillation
  attacks,&quot; after accusing three AI companies of misusing its Claude
  chatbot. O...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Chatgpt
  - Openai
category: General AI
source: >-
  https://www.engadget.com/ai/anthropic-accuses-three-chinese-ai-labs-of-abusing-claude-to-improve-their-own-models-205210613.html?src=rss
---
<p>Anthropic is issuing a call to action against AI &quot;distillation attacks,&quot; after accusing three AI companies of misusing its <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" class="no-affiliate-link" href="https://www.engadget.com/ai/anthropic-beefs-up-claudes-free-tier-as-openai-prepares-to-stuff-ads-into-chatgpts-194100939.html">Claude chatbot</a>. On its website, <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" class="no-affiliate-link" href="https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks">Anthropic</a> claimed that <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1" class="no-affiliate-link" href="https://www.engadget.com/ai/commerce-department-divisions-reportedly-ban-deepseek-from-government-devices-140916241.html">DeepSeek</a>, Moonshot and MiniMax have been conducting &quot;industrial-scale campaigns…to illicitly extract Claude’s capabilities to improve their own models.&quot;</p>
<p>Distillation in the AI world refers to when less capable models lean on the responses of more powerful ones to train themselves. While distillation isn&#39;t a bad thing across the board, Anthropic said that these types of attacks can be used in a more nefarious way. According to Anthropic, these three Chinese AI firms were responsible for more than &quot;16 million exchanges with Claude through approximately 24,000 fraudulent accounts.&quot; From Anthropic&#39;s perspective, these competing companies were using Claude as a shortcut to develop more advanced AI models, which could also lead to circumventing <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" class="no-affiliate-link" href="https://www.engadget.com/ai/anthropics-claude-ai-now-has-the-ability-to-end-distressing-conversations-201427401.html">certain safeguards</a>.</p>
<span id="end-legacy-contents"></span><p>Anthropic said in its post that it was able to link each of these distilling attack campaigns to the specific companies with &quot;high confidence&quot; thanks to IP address correlation, metadata requests and infrastructure indicators, along with corroborating with others in the AI industry who have noticed similar behaviors.</p>
<p>Early last year, <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1" class="no-affiliate-link" href="https://www.engadget.com/ai/openai-suddenly-thinks-intellectual-property-theft-is-not-cool-actually-amid-deepseeks-rise-154249605.html">OpenAI</a> made similar claims of rival firms distilling its models and banned suspected accounts in response. As for Anthropic, the company behind Claude said it would upgrade its system to make distillation attacks harder to do and easier to identify. While Anthropic is pointing fingers at these other firms, it&#39;s also facing a <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1" class="no-affiliate-link" href="https://www.engadget.com/ai/music-publishers-sue-anthropic-for-3-billion-over-flagrant-piracy-185459358.html">lawsuit</a> from music publishers who accused the AI company of using illegal copies of songs to train its Claude chatbot.</p>This article originally appeared on Engadget at https://www.engadget.com/ai/anthropic-accuses-three-chinese-ai-labs-of-abusing-claude-to-improve-their-own-models-205210613.html?src=rss
