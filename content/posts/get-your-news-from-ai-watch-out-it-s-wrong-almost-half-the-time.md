---
title: Get your news from AI? Watch out - it's wrong almost half the time
date: '2025-10-24'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence Get your news from AI?
  Watch out - it's wrong almost half the time New research from the European
  B...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Chatgpt
  - Tools
category: General AI
source: >-
  https://www.zdnet.com/article/get-your-news-from-ai-watch-out-its-wrong-almost-half-the-time/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    Get your news from AI? Watch out - it's wrong almost half the time
     
    New research from the European Broadcasting Union and the BBC has found that four leading chatbots routinely generate flawed summaries of news stories.
      Written by 
            Webb Wright, Contributing WriterContributing Writer  Oct. 24, 2025 at 1:49 p.m. PT                           Iana Kunitsa/Moment via GettyFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysNew research shows that AI chatbots often distort news stories.45% of the AI responses analyzed were found to be problematic.The authors warn of serious political and social consequences.A new study conducted by the European Broadcasting Union (EBU) and the BBC has found that leading AI chatbots routinely distort and misrepresent news stories. The consequence could be large-scale erosion in public trust towards news organizations and in the stability of democracy itself, the organizations warn.Spanning 18 countries and 14 languages, the study involved professional journalists evaluating thousands of responses from ChatGPT, Copilot, Gemini, and Perplexity about recent news stories based on criteria like accuracy, sourcing, and the differentiation of fact from opinion.Also: This free Google AI course could transform how you research and write - but act fastThe researchers found that close to half (45%) of all of the responses generated by the four AI systems "had at least one significant issue," according to the BBC, while many (20%) "contained major accuracy issues," such as hallucination -- i.e., fabricating information and presenting it as fact -- or providing outdated information. Google's Gemini had the worst performance of all, with 76% of its responses containing significant issues, especially regarding sourcing.ImplicationsThe study arrives at a time when generative AI tools are encroaching upon traditi
