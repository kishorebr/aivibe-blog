---
title: >-
  Sources: Project SGLang spins out as RadixArk with $400M valuation as
  inference market explodes
date: '2026-01-21'
excerpt: >-
  A pattern is emerging in the AI infrastructure world: popular open source
  tools are transforming into venture-backed startups worth hundreds of
  millio...
coverImage: >-
  https://images.unsplash.com/photo-1677442136019-21780ecad995?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Tools
category: General AI
source: >-
  https://techcrunch.com/2026/01/21/sources-project-sglang-spins-out-as-radixark-with-400m-valuation-as-inference-market-explodes/
---
A pattern is emerging in the AI infrastructure world: popular open source tools are transforming into venture-backed startups worth hundreds of millions of dollars. The latest example is RadixArk, the commercial company behind SGLang, an increasingly popular tool that helps AI models run faster and cheaper.

RadixArk was recently valued at about $400 million in a funding round led by Accel, according to two people familiar with the matter, a notable amount for a startup that was only announced last August. TechCrunch could not confirm the size of the funding.


	
	




	
	



The news comes as some of the team responsible for maintaining SGLang, which is used by companies like xAI and Cursor to accelerate AI model training, has transitioned to the recently launched commercial startup. RadixArk originated as SGLang in 2023 inside the UC Berkeley lab of Databricks co-founder Ion Stoica.

The startup previously raised angel capital from investors, including Intel CEO Lip-Bu Tan, the people said.

Ying Sheng, a key contributor to SGLang and a former engineer at xAI, left Elon Musk’s AI startup to become the co-founder and CEO of RadixArk, according to a LinkedIn announcement she made last month. Sheng was previously a research scientist at Databricks.

RadixArk’s Ying Sheng, Accel, and Lip-Bu Tan did not respond to a request for comment.

Both SGLang and RadixArk focus on optimizing inference processing — essentially allowing models to run faster and more efficiently on the same hardware. Together with model training, inference represents a large portion of the server costs associated with AI services. As a result, tools that optimize the process can create enormous savings almost immediately.

	
		
					
		Techcrunch event
		
			
				
											Disrupt 2026 Tickets: One-time offer
																Tickets are live! Save up to $680 while these rates last, and be among the first 500 registrants to get 50% off your +1 pass. TechCrunch Disrupt brings top leaders from Googl
