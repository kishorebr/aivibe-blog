---
title: >-
  Can one state save us from AI disaster? Inside California's new legislative
  crackdown
date: '2025-12-31'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence Can one state save us from
  AI disaster? Inside California's new legislative crackdown With no feder...
coverImage: >-
  https://images.unsplash.com/photo-1549317661-bd32c8ce0db2?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
category: Transportation
source: 'https://www.zdnet.com/article/california-ai-law-crackdown-on-risks/'
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    Can one state save us from AI disaster? Inside California's new legislative crackdown
     
    With no federal rules in place, state lawmakers are stepping in to regulate AI safety themselves.
      Written by 
            Webb Wright, Contributing WriterContributing Writer  Dec. 31, 2025 at 9:37 a.m. PT                            iStock / Getty Images Plus / Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysCalifornia's new AI safety law goes into effect Jan. 1.It centers on transparency and whistleblower protections.Some AI safety experts say the tech is evolving too quickly.A new California law going into effect Thursday, Jan. 1, aims to add a measure of transparency and accountability to the AI industry at a time when some experts are warning that the technology could potentially escape human control and cause catastrophe.Originally authored by state Democrat Scott Wiener, the law requires companies developing frontier AI models to publish information on their websites detailing their plans and policies for responding to "catastrophic risk," and to notify state authorities about any "critical safety incident" within fifteen days. Fines for failing to meet these terms can reach up to $1 million per violation. Also: Why complex reasoning models could make misbehaving AI easier to catchThe new law also provides whistleblower protections to employees of companies developing AI models. The legislation defines catastrophic risk as a scenario in which an advanced AI model kills or injures more than 50 people or causes material damages exceeding $1 billion, for example by providing instructions on how to develop chemical, biological, or nuclear weapons. "Unless they are developed with careful diligence and reasonable precaution, there is concern that advanced artificial intelligence systems could have capabilities that pose catastrophic r
