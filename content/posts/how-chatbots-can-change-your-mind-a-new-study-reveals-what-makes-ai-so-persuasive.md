---
title: >-
  How chatbots can change your mind - a new study reveals what makes AI so
  persuasive
date: '2025-12-06'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence How chatbots can change
  your mind - a new study reveals what makes AI so persuasive The more persua...
coverImage: >-
  https://images.unsplash.com/photo-1576091160399-112ba8d25d1f?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Llm
  - Tools
category: Healthcare
source: >-
  https://www.zdnet.com/article/how-chatbots-can-change-your-mind-a-new-study-reveals-what-makes-ai-so-persuasive/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    How chatbots can change your mind - a new study reveals what makes AI so persuasive
     
    The more persuasive a model is trained to be, the higher the likelihood that it'll hallucinate, researchers find.
      Written by 
            Webb Wright, Contributing WriterContributing Writer  Dec. 6, 2025 at 3:01 a.m. PT                            stellalevi/DigitalVision Vectors via Getty ImagesFollow ZDNET: Add us as a preferred source on Google.ZDNET's key takeawaysInteracting with chatbots can shift users' beliefs and opinions.A newly published study aimed to figure out why.Post-training and information density were key factors.Most of us feel a sense of personal ownership over our opinions: "I believe what I believe, not because I've been told to do so, but as the result of careful consideration.""I have full control over how, when, and why I change my mind."A new study, however, reveals that our beliefs are more susceptible to manipulation than we would like to believe -- and at the hands of chatbots. Also: Get your news from AI? Watch out - it's wrong almost half the timePublished Thursday in the journal Science, the study addressed increasingly urgent questions about our relationship with conversational AI tools: What is it about these systems that causes them to exert such a strong influence over users' worldviews? And how might this be used by nefarious actors to manipulate and control us in the future?The new study sheds light on some of the mechanisms within LLMs that can tug at the strings of human psychology. As the authors note, these can be exploited by bad actors for their own gain. However, they could also become a greater focus for developers, policymakers, and advocacy groups in their efforts to foster a healthier relationship between humans and AI."Large language models (LLMs) can now engage in sophisticated interactive dialogue, enabling a powerful mod
