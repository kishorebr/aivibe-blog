---
title: >-
  Google’s answer to the AI arms race — promote the guy behind its data center
  tech
date: '2025-12-11'
excerpt: >-
  Google just made a major move in the AI infrastructure arms race, elevating
  Amin Vahdat to chief technologist for AI infrastructure, a newly created p...
coverImage: >-
  https://images.unsplash.com/photo-1503676260728-1c00da094a0b?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Openai
  - Work
category: Education
source: >-
  https://techcrunch.com/2025/12/10/googles-answer-to-the-ai-arms-race-promote-the-guy-behind-its-data-center-tech/
---
Google just made a major move in the AI infrastructure arms race, elevating Amin Vahdat to chief technologist for AI infrastructure, a newly created position reporting directly to CEO Sundar Pichai, according to a memo first reported by Semafor and later confirmed by TechCrunch. It’s a signal of just how critical this work has become as Google pours up to $93 billion into capital expenditures by the end of 2025 — a number that parent company Alphabet expects will be a whole lot bigger next year.

Vahdat isn’t new to the game. The computer scientist, who holds a PhD from UC Berkeley and started as a research intern at Xerox PARC back in the early ’90s, has been quietly building Google’s AI backbone for the past 15 years. Before joining Google in 2010 as an engineering fellow and VP, he was an associate professor at Duke University and later a professor and SAIC Chair at UC San Diego. His academic credentials are formidable — with what appears to be around 395 published papers — and his research has always focused on making computers work more efficiently at massive scale.


	
	




	
	



Vahdat already maintains a high profile with Google. Just eight months ago, at Google Cloud Next, he took the stage to unveil the company’s seventh-generation TPU, called Ironwood, in his role as VP and GM of ML, Systems, and Cloud AI. The specs he rattled off at the event were staggering, too: over 9,000 chips per pod delivering 42.5 exaflops of compute — more than 24 times the power of the world’s No. 1 supercomputer at the time, he said. “Demand for AI compute has increased by a factor of 100 million in just eight years,” he told the audience.

Behind the scenes, as noted by Semafor, Vahdat has been orchestrating the unglamorous and essential work that keeps Google competitive, including those custom TPU chips for AI training and inference that give Google an edge over rivals like OpenAI, as well as the Jupiter network, the super-fast internal network that allows all its servers 
