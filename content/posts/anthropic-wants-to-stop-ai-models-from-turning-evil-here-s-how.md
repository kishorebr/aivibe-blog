---
title: Anthropic wants to stop AI models from turning evil - here's how
date: '2025-08-04'
excerpt: >-
  Innovation Home Innovation Artificial Intelligence Anthropic wants to stop AI
  models from turning evil - here's how Can a new approach to AI model tra...
coverImage: >-
  https://images.unsplash.com/photo-1503676260728-1c00da094a0b?w=400&h=200&fit=crop&auto=format
author: AIVibe
tags:
  - Ai
  - Openai
  - Education
  - Work
  - Tools
category: Education
source: >-
  https://www.zdnet.com/article/anthropic-wants-to-stop-ai-models-from-turning-evil-heres-how/
---
Innovation      
      Home
    
      Innovation
    
      Artificial Intelligence
       
    Anthropic wants to stop AI models from turning evil - here's how
     
    Can a new approach to AI model training prevent systems from absorbing harmful data?
      Written by 
            Radhika Rajkumar, EditorEditor  Aug. 4, 2025 at 12:30 p.m. PT                           Lyudmila Lucienne/GettyZDNET's key takeawaysNew research from Anthropic identifies model characteristics, called persona vectors. This helps catch bad behavior without impacting performance.Still, developers don't know enough about why models hallucinate and behave in evil ways. Why do models hallucinate, make violent suggestions, or overly agree with users? Generally, researchers don't really know. But Anthropic just found new insights that could help stop this behavior before it happens. In a paper released Friday, the company explores how and why models exhibit undesirable behavior, and what can be done about it. A model's persona can change during training and once it's deployed, when user inputs start influencing it. This is evidenced by models that may have passed safety checks before deployment, but then develop alter egos or act erratically once they're publicly available -- like when OpenAI recalled GPT-4o for being too agreeable. See also when Microsoft's Bing chatbot revealed its internal codename, Sydney, in 2023, or Grok's recent antisemitic tirade. Why it matters AI usage is on the rise; models are increasingly embedded in everything from education tools to autonomous systems, making how they behave even more important -- especially as safety teams dwindle and AI regulation doesn't really materialize. That said, President Donald Trump's recent AI Action Plan did mention the importance of interpretability -- or the ability to understand how models make decisions -- which persona vectors add to. How persona vectors work Testing approaches on Qwen 2.5-7B-Instruct and Llama-3.1-8B-Instruc
